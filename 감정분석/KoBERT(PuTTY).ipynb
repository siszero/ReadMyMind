{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ac9bf8",
   "metadata": {},
   "source": [
    "# 1. KoBERT 사용을 위한 환경설정(PuTTY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "280e5131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gluonnlp in ./anaconda3/lib/python3.9/site-packages (0.10.0)\n",
      "Requirement already satisfied: pandas in ./anaconda3/lib/python3.9/site-packages (1.3.4)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.9/site-packages (4.62.3)\n",
      "Requirement already satisfied: cython in ./anaconda3/lib/python3.9/site-packages (from gluonnlp) (0.29.24)\n",
      "Requirement already satisfied: packaging in ./anaconda3/lib/python3.9/site-packages (from gluonnlp) (21.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in ./anaconda3/lib/python3.9/site-packages (from gluonnlp) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./anaconda3/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./anaconda3/lib/python3.9/site-packages (from packaging->gluonnlp) (3.0.4)\n",
      "Requirement already satisfied: mxnet in ./anaconda3/lib/python3.9/site-packages (1.9.0)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in ./anaconda3/lib/python3.9/site-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in ./anaconda3/lib/python3.9/site-packages (from mxnet) (1.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in ./anaconda3/lib/python3.9/site-packages (from mxnet) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/lib/python3.9/site-packages (from requests<3,>=2.20.0->mxnet) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.9/site-packages (from requests<3,>=2.20.0->mxnet) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.9/site-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./anaconda3/lib/python3.9/site-packages (from requests<3,>=2.20.0->mxnet) (2.0.4)\n",
      "Requirement already satisfied: sentencepiece==0.1.94 in ./anaconda3/lib/python3.9/site-packages (0.1.94)\n",
      "Requirement already satisfied: transformers==4.8.2 in ./anaconda3/lib/python3.9/site-packages (4.8.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./anaconda3/lib/python3.9/site-packages (from transformers==4.8.2) (2021.8.3)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.9/site-packages (from transformers==4.8.2) (3.3.1)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in ./anaconda3/lib/python3.9/site-packages (from transformers==4.8.2) (0.0.12)\n",
      "Requirement already satisfied: packaging in ./anaconda3/lib/python3.9/site-packages (from transformers==4.8.2) (21.0)\n",
      "Requirement already satisfied: requests in ./anaconda3/lib/python3.9/site-packages (from transformers==4.8.2) (2.26.0)\n",
      "Requirement already satisfied: pyyaml in ./anaconda3/lib/python3.9/site-packages (from transformers==4.8.2) (6.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in ./anaconda3/lib/python3.9/site-packages (from transformers==4.8.2) (0.10.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./anaconda3/lib/python3.9/site-packages (from transformers==4.8.2) (1.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./anaconda3/lib/python3.9/site-packages (from transformers==4.8.2) (4.62.3)\n",
      "Requirement already satisfied: sacremoses in ./anaconda3/lib/python3.9/site-packages (from transformers==4.8.2) (0.0.49)\n",
      "Requirement already satisfied: typing-extensions in ./anaconda3/lib/python3.9/site-packages (from huggingface-hub==0.0.12->transformers==4.8.2) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./anaconda3/lib/python3.9/site-packages (from packaging->transformers==4.8.2) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./anaconda3/lib/python3.9/site-packages (from requests->transformers==4.8.2) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.9/site-packages (from requests->transformers==4.8.2) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.9/site-packages (from requests->transformers==4.8.2) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/lib/python3.9/site-packages (from requests->transformers==4.8.2) (1.26.7)\n",
      "Requirement already satisfied: six in ./anaconda3/lib/python3.9/site-packages (from sacremoses->transformers==4.8.2) (1.16.0)\n",
      "Requirement already satisfied: click in ./anaconda3/lib/python3.9/site-packages (from sacremoses->transformers==4.8.2) (8.0.3)\n",
      "Requirement already satisfied: joblib in ./anaconda3/lib/python3.9/site-packages (from sacremoses->transformers==4.8.2) (1.1.0)\n",
      "Requirement already satisfied: torch in ./anaconda3/lib/python3.9/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in ./anaconda3/lib/python3.9/site-packages (from torch) (3.10.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gluonnlp pandas tqdm\n",
    "!pip install mxnet\n",
    "!pip install sentencepiece==0.1.94\n",
    "!pip install transformers==4.8.2\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4851774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kobert_tokenizer\n",
      "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-trakuful/kobert-tokenizer_f42281780abd4f4697aafa0e4cf61aaf\n",
      "  Running command git clone -q https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-trakuful/kobert-tokenizer_f42281780abd4f4697aafa0e4cf61aaf\n",
      "  Resolved https://github.com/SKTBrain/KoBERT.git to commit e1f2f37055e7460d8427f6912579c0162cb69831\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "794b5dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kobert-transformers in ./anaconda3/lib/python3.9/site-packages (0.5.1)\n",
      "Requirement already satisfied: sentencepiece>=0.1.91 in ./anaconda3/lib/python3.9/site-packages (from kobert-transformers) (0.1.94)\n",
      "Requirement already satisfied: torch>=1.1.0 in ./anaconda3/lib/python3.9/site-packages (from kobert-transformers) (1.11.0)\n",
      "Requirement already satisfied: transformers<5,>=3 in ./anaconda3/lib/python3.9/site-packages (from kobert-transformers) (4.8.2)\n",
      "Requirement already satisfied: typing-extensions in ./anaconda3/lib/python3.9/site-packages (from torch>=1.1.0->kobert-transformers) (3.10.0.2)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in ./anaconda3/lib/python3.9/site-packages (from transformers<5,>=3->kobert-transformers) (0.0.12)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.9/site-packages (from transformers<5,>=3->kobert-transformers) (3.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./anaconda3/lib/python3.9/site-packages (from transformers<5,>=3->kobert-transformers) (2021.8.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./anaconda3/lib/python3.9/site-packages (from transformers<5,>=3->kobert-transformers) (1.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./anaconda3/lib/python3.9/site-packages (from transformers<5,>=3->kobert-transformers) (4.62.3)\n",
      "Requirement already satisfied: pyyaml in ./anaconda3/lib/python3.9/site-packages (from transformers<5,>=3->kobert-transformers) (6.0)\n",
      "Requirement already satisfied: sacremoses in ./anaconda3/lib/python3.9/site-packages (from transformers<5,>=3->kobert-transformers) (0.0.49)\n",
      "Requirement already satisfied: packaging in ./anaconda3/lib/python3.9/site-packages (from transformers<5,>=3->kobert-transformers) (21.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in ./anaconda3/lib/python3.9/site-packages (from transformers<5,>=3->kobert-transformers) (0.10.3)\n",
      "Requirement already satisfied: requests in ./anaconda3/lib/python3.9/site-packages (from transformers<5,>=3->kobert-transformers) (2.26.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./anaconda3/lib/python3.9/site-packages (from packaging->transformers<5,>=3->kobert-transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/lib/python3.9/site-packages (from requests->transformers<5,>=3->kobert-transformers) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./anaconda3/lib/python3.9/site-packages (from requests->transformers<5,>=3->kobert-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.9/site-packages (from requests->transformers<5,>=3->kobert-transformers) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.9/site-packages (from requests->transformers<5,>=3->kobert-transformers) (2021.10.8)\n",
      "Requirement already satisfied: six in ./anaconda3/lib/python3.9/site-packages (from sacremoses->transformers<5,>=3->kobert-transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in ./anaconda3/lib/python3.9/site-packages (from sacremoses->transformers<5,>=3->kobert-transformers) (1.1.0)\n",
      "Requirement already satisfied: click in ./anaconda3/lib/python3.9/site-packages (from sacremoses->transformers<5,>=3->kobert-transformers) (8.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install kobert-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a3425a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/piai/.cache/kobert_v1.zip\n",
      "using cached model. /home/piai/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "# from transformers import Adamw\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0048a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4958, 6855, 2046, 7088, 1050, 7843, 54, 3]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "tokenizer.encode(\"한국어 모델을 공유합니다.\")\n",
    "[2, 4958, 6855, 2046, 7088, 1050, 7843, 54, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49781b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4958, 6855, 2046, 7088, 1023, 7063, 7843, 54, 3]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1', sp_model_kwargs={'nbest_size': -1, 'alpha': 0.6, 'enable_sampling': True})\n",
    "tokenizer.encode(\"한국어 모델을 공유합니다.\")\n",
    "[2, 4958, 6855, 2046, 7088, 1023, 7063, 7843, 54, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b001c5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "model = BertModel.from_pretrained('skt/kobert-base-v1')\n",
    "text = \"한국어 모델을 공유합니다.\"\n",
    "inputs = tokenizer.batch_encode_plus([text])\n",
    "out = model(input_ids = torch.tensor(inputs['input_ids']),\n",
    "        attention_mask = torch.tensor(inputs['attention_mask']))\n",
    "out.pooler_output.shape\n",
    "torch.Size([1, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8275e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast, BartModel\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-base-v1')\n",
    "model = BartModel.from_pretrained('gogamza/kobart-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da1e21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kobert.pytorch_kobert import get_kobert_model\n",
    "# from kobert_tokenizer import KoBERTTokenizer\n",
    "# tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "# bertmodel, vocab = get_kobert_model('skt/kobert-base-v1', tokenizer.vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67b2b88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in ./anaconda3/lib/python3.9/site-packages (7.6.5)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./anaconda3/lib/python3.9/site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in ./anaconda3/lib/python3.9/site-packages (from ipywidgets) (7.29.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in ./anaconda3/lib/python3.9/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in ./anaconda3/lib/python3.9/site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in ./anaconda3/lib/python3.9/site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in ./anaconda3/lib/python3.9/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in ./anaconda3/lib/python3.9/site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in ./anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in ./anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: jupyter-client<8.0 in ./anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in ./anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.4.1)\n",
      "Requirement already satisfied: pexpect>4.3 in ./anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in ./anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in ./anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: backcall in ./anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in ./anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in ./anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (58.0.4)\n",
      "Requirement already satisfied: pygments in ./anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in ./anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./anaconda3/lib/python3.9/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in ./anaconda3/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: pyzmq>=13 in ./anaconda3/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in ./anaconda3/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in ./anaconda3/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: six>=1.11.0 in ./anaconda3/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in ./anaconda3/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in ./anaconda3/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./anaconda3/lib/python3.9/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./anaconda3/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in ./anaconda3/lib/python3.9/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.5)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.4)\n",
      "Requirement already satisfied: prometheus-client in ./anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.11.0)\n",
      "Requirement already satisfied: nbconvert in ./anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.1.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in ./anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi in ./anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
      "Requirement already satisfied: cffi>=1.0.0 in ./anaconda3/lib/python3.9/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.6)\n",
      "Requirement already satisfied: pycparser in ./anaconda3/lib/python3.9/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in ./anaconda3/lib/python3.9/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: testpath in ./anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: bleach in ./anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.0.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in ./anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in ./anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.3)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in ./anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: defusedxml in ./anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: async-generator in ./anaconda3/lib/python3.9/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in ./anaconda3/lib/python3.9/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: webencodings in ./anaconda3/lib/python3.9/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in ./anaconda3/lib/python3.9/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./anaconda3/lib/python3.9/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.4)\n",
      "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
      "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-x7h8lrlf\n",
      "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-x7h8lrlf\n",
      "  Resolved https://****@github.com/SKTBrain/KoBERT.git to commit e1f2f37055e7460d8427f6912579c0162cb69831\n",
      "Requirement already satisfied: boto3 in ./anaconda3/lib/python3.9/site-packages (from kobert==0.2.3) (1.21.32)\n",
      "Requirement already satisfied: gluonnlp>=0.6.0 in ./anaconda3/lib/python3.9/site-packages (from kobert==0.2.3) (0.10.0)\n",
      "Requirement already satisfied: mxnet>=1.4.0 in ./anaconda3/lib/python3.9/site-packages (from kobert==0.2.3) (1.9.0)\n",
      "Requirement already satisfied: onnxruntime==1.8.0 in ./anaconda3/lib/python3.9/site-packages (from kobert==0.2.3) (1.8.0)\n",
      "Requirement already satisfied: sentencepiece>=0.1.6 in ./anaconda3/lib/python3.9/site-packages (from kobert==0.2.3) (0.1.94)\n",
      "Requirement already satisfied: torch>=1.7.0 in ./anaconda3/lib/python3.9/site-packages (from kobert==0.2.3) (1.11.0)\n",
      "Requirement already satisfied: transformers>=4.8.1 in ./anaconda3/lib/python3.9/site-packages (from kobert==0.2.3) (4.8.2)\n",
      "Requirement already satisfied: numpy>=1.16.6 in ./anaconda3/lib/python3.9/site-packages (from onnxruntime==1.8.0->kobert==0.2.3) (1.20.3)\n",
      "Requirement already satisfied: flatbuffers in ./anaconda3/lib/python3.9/site-packages (from onnxruntime==1.8.0->kobert==0.2.3) (2.0)\n",
      "Requirement already satisfied: protobuf in ./anaconda3/lib/python3.9/site-packages (from onnxruntime==1.8.0->kobert==0.2.3) (3.20.0)\n",
      "Requirement already satisfied: packaging in ./anaconda3/lib/python3.9/site-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (21.0)\n",
      "Requirement already satisfied: cython in ./anaconda3/lib/python3.9/site-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (0.29.24)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in ./anaconda3/lib/python3.9/site-packages (from mxnet>=1.4.0->kobert==0.2.3) (0.8.4)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in ./anaconda3/lib/python3.9/site-packages (from mxnet>=1.4.0->kobert==0.2.3) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/lib/python3.9/site-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./anaconda3/lib/python3.9/site-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.9/site-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.9/site-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2021.10.8)\n",
      "Requirement already satisfied: typing-extensions in ./anaconda3/lib/python3.9/site-packages (from torch>=1.7.0->kobert==0.2.3) (3.10.0.2)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.9/site-packages (from transformers>=4.8.1->kobert==0.2.3) (3.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./anaconda3/lib/python3.9/site-packages (from transformers>=4.8.1->kobert==0.2.3) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in ./anaconda3/lib/python3.9/site-packages (from transformers>=4.8.1->kobert==0.2.3) (0.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in ./anaconda3/lib/python3.9/site-packages (from transformers>=4.8.1->kobert==0.2.3) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in ./anaconda3/lib/python3.9/site-packages (from transformers>=4.8.1->kobert==0.2.3) (0.0.49)\n",
      "Requirement already satisfied: pyyaml in ./anaconda3/lib/python3.9/site-packages (from transformers>=4.8.1->kobert==0.2.3) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./anaconda3/lib/python3.9/site-packages (from transformers>=4.8.1->kobert==0.2.3) (2021.8.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./anaconda3/lib/python3.9/site-packages (from packaging->gluonnlp>=0.6.0->kobert==0.2.3) (3.0.4)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in ./anaconda3/lib/python3.9/site-packages (from boto3->kobert==0.2.3) (1.0.0)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.32 in ./anaconda3/lib/python3.9/site-packages (from boto3->kobert==0.2.3) (1.24.32)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in ./anaconda3/lib/python3.9/site-packages (from boto3->kobert==0.2.3) (0.5.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./anaconda3/lib/python3.9/site-packages (from botocore<1.25.0,>=1.24.32->boto3->kobert==0.2.3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.32->boto3->kobert==0.2.3) (1.16.0)\n",
      "Requirement already satisfied: click in ./anaconda3/lib/python3.9/site-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.3) (8.0.3)\n",
      "Requirement already satisfied: joblib in ./anaconda3/lib/python3.9/site-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.3) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets  # for vscode\n",
    "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d046c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobert import get_tokenizer\n",
    "from kobert import get_pytorch_kobert_model\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a92ea9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/piai/.cache/kobert_v1.zip\n",
      "using cached model. /home/piai/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc32282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-06 21:30:04--  http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_train.txt\n",
      "Resolving skt-lsl-nlp-model.s3.amazonaws.com (skt-lsl-nlp-model.s3.amazonaws.com)... 52.219.146.46\n",
      "접속 skt-lsl-nlp-model.s3.amazonaws.com (skt-lsl-nlp-model.s3.amazonaws.com)|52.219.146.46|:80... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14628807 (14M) [text/plain]\n",
      "Saving to: ‘.cache/ratings_train.txt’\n",
      "\n",
      ".cache/ratings_trai 100%[===================>]  13.95M  44.5MB/s    in 0.3s    \n",
      "\n",
      "2022-04-06 21:30:05 (44.5 MB/s) - ‘.cache/ratings_train.txt’ saved [14628807/14628807]\n",
      "\n",
      "--2022-04-06 21:30:05--  http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_test.txt\n",
      "Resolving skt-lsl-nlp-model.s3.amazonaws.com (skt-lsl-nlp-model.s3.amazonaws.com)... 52.219.146.46\n",
      "접속 skt-lsl-nlp-model.s3.amazonaws.com (skt-lsl-nlp-model.s3.amazonaws.com)|52.219.146.46|:80... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4893335 (4.7M) [text/plain]\n",
      "Saving to: ‘.cache/ratings_test.txt’\n",
      "\n",
      ".cache/ratings_test 100%[===================>]   4.67M  21.6MB/s    in 0.2s    \n",
      "\n",
      "2022-04-06 21:30:05 (21.6 MB/s) - ‘.cache/ratings_test.txt’ saved [4893335/4893335]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O .cache/ratings_train.txt http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_train.txt\n",
    "!wget -O .cache/ratings_test.txt http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586256d",
   "metadata": {},
   "source": [
    "# 2. 데이터 정제작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de592427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f6e0bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('AIData/4차년도.csv', encoding='cp949')\n",
    "data2 = pd.read_csv('AIData/5차년도.csv', encoding='cp949')\n",
    "data3 = pd.read_csv('AIData/5차년도_2차.csv', encoding='cp949')\n",
    "data4 = pd.read_csv('AIData/추가데이터.csv', encoding='cp949')\n",
    "raw_df = pd.concat([data1, data2, data3, data4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e015d3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_id</th>\n",
       "      <th>발화문</th>\n",
       "      <th>상황</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e258fd1305bcf3ad153a6a4</td>\n",
       "      <td>어, 청소 니가 대신 해 줘!</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e258fe2305bcf3ad153a6a5</td>\n",
       "      <td>둘 다 청소 하기 싫어. 귀찮아.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e258ff5305bcf3ad153a6a6</td>\n",
       "      <td>둘 다 하기 싫어서 화내.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5e25902f305bcf3ad153a6a9</td>\n",
       "      <td>그럼 방세는 어떡해.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5e27f90b5807b852d9e0157b</td>\n",
       "      <td>권태긴줄 알았는데 다른 사람이 생겼나보더라고.</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11564</th>\n",
       "      <td>NaN</td>\n",
       "      <td>올해 은퇴해서 사회를 벗어나 여행도 다니며 느긋하게 살고 있는데 너무 행복해.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11565</th>\n",
       "      <td>NaN</td>\n",
       "      <td>엄마가 나를 잘 대해줘서 기분이 좋아.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11566</th>\n",
       "      <td>NaN</td>\n",
       "      <td>겨울에 아빠랑 시골에 갔을 때 기쁘고 행복했어.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11567</th>\n",
       "      <td>NaN</td>\n",
       "      <td>이제야 생활에 조금은 여유가 생긴 것 같아 숨통이 트여.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11568</th>\n",
       "      <td>NaN</td>\n",
       "      <td>부동산 임대 소득으로 현재 여유롭게 살 수 있어서 좋단다.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         wav_id                                          발화문  \\\n",
       "0      5e258fd1305bcf3ad153a6a4                             어, 청소 니가 대신 해 줘!   \n",
       "1      5e258fe2305bcf3ad153a6a5                           둘 다 청소 하기 싫어. 귀찮아.   \n",
       "2      5e258ff5305bcf3ad153a6a6                               둘 다 하기 싫어서 화내.   \n",
       "3      5e25902f305bcf3ad153a6a9                                  그럼 방세는 어떡해.   \n",
       "4      5e27f90b5807b852d9e0157b                    권태긴줄 알았는데 다른 사람이 생겼나보더라고.   \n",
       "...                         ...                                          ...   \n",
       "11564                       NaN  올해 은퇴해서 사회를 벗어나 여행도 다니며 느긋하게 살고 있는데 너무 행복해.   \n",
       "11565                       NaN                        엄마가 나를 잘 대해줘서 기분이 좋아.   \n",
       "11566                       NaN                   겨울에 아빠랑 시골에 갔을 때 기쁘고 행복했어.   \n",
       "11567                       NaN              이제야 생활에 조금은 여유가 생긴 것 같아 숨통이 트여.   \n",
       "11568                       NaN             부동산 임대 소득으로 현재 여유롭게 살 수 있어서 좋단다.   \n",
       "\n",
       "          상황  \n",
       "0      anger  \n",
       "1      anger  \n",
       "2      anger  \n",
       "3      anger  \n",
       "4        sad  \n",
       "...      ...  \n",
       "11564  peace  \n",
       "11565  peace  \n",
       "11566  peace  \n",
       "11567  peace  \n",
       "11568  peace  \n",
       "\n",
       "[55560 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.drop(['1번 감정','1번 감정세기','2번 감정','2번 감정세기', '3번 감정', '3번 감정세기','4번 감정','4번감정세기'\n",
    "            ,'5번 감정','5번 감정세기','나이','성별'],axis=1,inplace=True)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "255690fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_id</th>\n",
       "      <th>발화문</th>\n",
       "      <th>상황</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e258fd1305bcf3ad153a6a4</td>\n",
       "      <td>어, 청소 니가 대신 해 줘!</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e258fe2305bcf3ad153a6a5</td>\n",
       "      <td>둘 다 청소 하기 싫어. 귀찮아.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e258ff5305bcf3ad153a6a6</td>\n",
       "      <td>둘 다 하기 싫어서 화내.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5e25902f305bcf3ad153a6a9</td>\n",
       "      <td>그럼 방세는 어떡해.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5e27f90b5807b852d9e0157b</td>\n",
       "      <td>권태긴줄 알았는데 다른 사람이 생겼나보더라고.</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11564</th>\n",
       "      <td>NaN</td>\n",
       "      <td>올해 은퇴해서 사회를 벗어나 여행도 다니며 느긋하게 살고 있는데 너무 행복해.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11565</th>\n",
       "      <td>NaN</td>\n",
       "      <td>엄마가 나를 잘 대해줘서 기분이 좋아.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11566</th>\n",
       "      <td>NaN</td>\n",
       "      <td>겨울에 아빠랑 시골에 갔을 때 기쁘고 행복했어.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11567</th>\n",
       "      <td>NaN</td>\n",
       "      <td>이제야 생활에 조금은 여유가 생긴 것 같아 숨통이 트여.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11568</th>\n",
       "      <td>NaN</td>\n",
       "      <td>부동산 임대 소득으로 현재 여유롭게 살 수 있어서 좋단다.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50060 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         wav_id                                          발화문  \\\n",
       "0      5e258fd1305bcf3ad153a6a4                             어, 청소 니가 대신 해 줘!   \n",
       "1      5e258fe2305bcf3ad153a6a5                           둘 다 청소 하기 싫어. 귀찮아.   \n",
       "2      5e258ff5305bcf3ad153a6a6                               둘 다 하기 싫어서 화내.   \n",
       "3      5e25902f305bcf3ad153a6a9                                  그럼 방세는 어떡해.   \n",
       "4      5e27f90b5807b852d9e0157b                    권태긴줄 알았는데 다른 사람이 생겼나보더라고.   \n",
       "...                         ...                                          ...   \n",
       "11564                       NaN  올해 은퇴해서 사회를 벗어나 여행도 다니며 느긋하게 살고 있는데 너무 행복해.   \n",
       "11565                       NaN                        엄마가 나를 잘 대해줘서 기분이 좋아.   \n",
       "11566                       NaN                   겨울에 아빠랑 시골에 갔을 때 기쁘고 행복했어.   \n",
       "11567                       NaN              이제야 생활에 조금은 여유가 생긴 것 같아 숨통이 트여.   \n",
       "11568                       NaN             부동산 임대 소득으로 현재 여유롭게 살 수 있어서 좋단다.   \n",
       "\n",
       "          상황  \n",
       "0      anger  \n",
       "1      anger  \n",
       "2      anger  \n",
       "3      anger  \n",
       "4        sad  \n",
       "...      ...  \n",
       "11564  peace  \n",
       "11565  peace  \n",
       "11566  peace  \n",
       "11567  peace  \n",
       "11568  peace  \n",
       "\n",
       "[50060 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#neutral, peace      0\n",
    "#surprise  제거\n",
    "#angry  화남      1\n",
    "#sadness  슬픔    2\n",
    "#neutral  제거\n",
    "#happiness  기쁨  3\n",
    "#disgust 화남\n",
    "## 기쁨,슬픔,화남,두려움==>(happiness,sadness,agry,neutral)\n",
    "spac = raw_df[raw_df['상황']=='surprise'].index\n",
    "raw_df.drop(spac,inplace=True)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3973dfaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_id</th>\n",
       "      <th>발화문</th>\n",
       "      <th>상황</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e258fd1305bcf3ad153a6a4</td>\n",
       "      <td>어, 청소 니가 대신 해 줘!</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e258fe2305bcf3ad153a6a5</td>\n",
       "      <td>둘 다 청소 하기 싫어. 귀찮아.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e258ff5305bcf3ad153a6a6</td>\n",
       "      <td>둘 다 하기 싫어서 화내.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5e25902f305bcf3ad153a6a9</td>\n",
       "      <td>그럼 방세는 어떡해.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5e27fb575807b852d9e01595</td>\n",
       "      <td>어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11559</th>\n",
       "      <td>NaN</td>\n",
       "      <td>친구들에게 왕따를 당하고 있어. 그래도 괜찮아.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11560</th>\n",
       "      <td>NaN</td>\n",
       "      <td>오랜 친구와 대화를 했더니 마음이 정말 편해.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11561</th>\n",
       "      <td>NaN</td>\n",
       "      <td>옆집 김 씨가 수술 자금을 빌려갔는데 천천히 갚으려고 하려고.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11562</th>\n",
       "      <td>NaN</td>\n",
       "      <td>회계 관련 일을 하는 며느리에게 노후 자금을 맡기기로 했어.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11568</th>\n",
       "      <td>NaN</td>\n",
       "      <td>부동산 임대 소득으로 현재 여유롭게 살 수 있어서 좋단다.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41418 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         wav_id                                 발화문     상황\n",
       "0      5e258fd1305bcf3ad153a6a4                    어, 청소 니가 대신 해 줘!  anger\n",
       "1      5e258fe2305bcf3ad153a6a5                  둘 다 청소 하기 싫어. 귀찮아.  anger\n",
       "2      5e258ff5305bcf3ad153a6a6                      둘 다 하기 싫어서 화내.  anger\n",
       "3      5e25902f305bcf3ad153a6a9                         그럼 방세는 어떡해.  anger\n",
       "6      5e27fb575807b852d9e01595        어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.  anger\n",
       "...                         ...                                 ...    ...\n",
       "11559                       NaN          친구들에게 왕따를 당하고 있어. 그래도 괜찮아.  peace\n",
       "11560                       NaN           오랜 친구와 대화를 했더니 마음이 정말 편해.  peace\n",
       "11561                       NaN  옆집 김 씨가 수술 자금을 빌려갔는데 천천히 갚으려고 하려고.  peace\n",
       "11562                       NaN   회계 관련 일을 하는 며느리에게 노후 자금을 맡기기로 했어.  peace\n",
       "11568                       NaN    부동산 임대 소득으로 현재 여유롭게 살 수 있어서 좋단다.  peace\n",
       "\n",
       "[41418 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spac = raw_df[raw_df['상황']=='neutral'].index\n",
    "raw_df.drop(spac,inplace=True)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d104f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_id</th>\n",
       "      <th>발화문</th>\n",
       "      <th>상황</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e258fd1305bcf3ad153a6a4</td>\n",
       "      <td>어, 청소 니가 대신 해 줘!</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e258fe2305bcf3ad153a6a5</td>\n",
       "      <td>둘 다 청소 하기 싫어. 귀찮아.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e258ff5305bcf3ad153a6a6</td>\n",
       "      <td>둘 다 하기 싫어서 화내.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5e25902f305bcf3ad153a6a9</td>\n",
       "      <td>그럼 방세는 어떡해.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5e27fb575807b852d9e01595</td>\n",
       "      <td>어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11550</th>\n",
       "      <td>NaN</td>\n",
       "      <td>나는 이 나이 먹고서도 한 번도 연애해 본 적이 없어.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11552</th>\n",
       "      <td>NaN</td>\n",
       "      <td>아이가 생기고 세상을 좀 더 따뜻한 시선으로 바라보게 된 것 같아.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11559</th>\n",
       "      <td>NaN</td>\n",
       "      <td>친구들에게 왕따를 당하고 있어. 그래도 괜찮아.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11561</th>\n",
       "      <td>NaN</td>\n",
       "      <td>옆집 김 씨가 수술 자금을 빌려갔는데 천천히 갚으려고 하려고.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11568</th>\n",
       "      <td>NaN</td>\n",
       "      <td>부동산 임대 소득으로 현재 여유롭게 살 수 있어서 좋단다.</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30997 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         wav_id                                    발화문     상황\n",
       "0      5e258fd1305bcf3ad153a6a4                       어, 청소 니가 대신 해 줘!  anger\n",
       "1      5e258fe2305bcf3ad153a6a5                     둘 다 청소 하기 싫어. 귀찮아.  anger\n",
       "2      5e258ff5305bcf3ad153a6a6                         둘 다 하기 싫어서 화내.  anger\n",
       "3      5e25902f305bcf3ad153a6a9                            그럼 방세는 어떡해.  anger\n",
       "6      5e27fb575807b852d9e01595           어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.  anger\n",
       "...                         ...                                    ...    ...\n",
       "11550                       NaN         나는 이 나이 먹고서도 한 번도 연애해 본 적이 없어.  peace\n",
       "11552                       NaN  아이가 생기고 세상을 좀 더 따뜻한 시선으로 바라보게 된 것 같아.  peace\n",
       "11559                       NaN             친구들에게 왕따를 당하고 있어. 그래도 괜찮아.  peace\n",
       "11561                       NaN     옆집 김 씨가 수술 자금을 빌려갔는데 천천히 갚으려고 하려고.  peace\n",
       "11568                       NaN       부동산 임대 소득으로 현재 여유롭게 살 수 있어서 좋단다.  peace\n",
       "\n",
       "[30997 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spac = raw_df[raw_df['상황']=='fear'].index\n",
    "raw_df.drop(spac,inplace=True)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c6f7fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_id</th>\n",
       "      <th>발화문</th>\n",
       "      <th>상황</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e258fd1305bcf3ad153a6a4</td>\n",
       "      <td>어, 청소 니가 대신 해 줘!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e258fe2305bcf3ad153a6a5</td>\n",
       "      <td>둘 다 청소 하기 싫어. 귀찮아.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e258ff5305bcf3ad153a6a6</td>\n",
       "      <td>둘 다 하기 싫어서 화내.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5e25902f305bcf3ad153a6a9</td>\n",
       "      <td>그럼 방세는 어떡해.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5e27fb575807b852d9e01595</td>\n",
       "      <td>어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11550</th>\n",
       "      <td>NaN</td>\n",
       "      <td>나는 이 나이 먹고서도 한 번도 연애해 본 적이 없어.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11552</th>\n",
       "      <td>NaN</td>\n",
       "      <td>아이가 생기고 세상을 좀 더 따뜻한 시선으로 바라보게 된 것 같아.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11559</th>\n",
       "      <td>NaN</td>\n",
       "      <td>친구들에게 왕따를 당하고 있어. 그래도 괜찮아.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11561</th>\n",
       "      <td>NaN</td>\n",
       "      <td>옆집 김 씨가 수술 자금을 빌려갔는데 천천히 갚으려고 하려고.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11568</th>\n",
       "      <td>NaN</td>\n",
       "      <td>부동산 임대 소득으로 현재 여유롭게 살 수 있어서 좋단다.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30997 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         wav_id                                    발화문 상황\n",
       "0      5e258fd1305bcf3ad153a6a4                       어, 청소 니가 대신 해 줘!  0\n",
       "1      5e258fe2305bcf3ad153a6a5                     둘 다 청소 하기 싫어. 귀찮아.  0\n",
       "2      5e258ff5305bcf3ad153a6a6                         둘 다 하기 싫어서 화내.  0\n",
       "3      5e25902f305bcf3ad153a6a9                            그럼 방세는 어떡해.  0\n",
       "6      5e27fb575807b852d9e01595           어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.  0\n",
       "...                         ...                                    ... ..\n",
       "11550                       NaN         나는 이 나이 먹고서도 한 번도 연애해 본 적이 없어.  3\n",
       "11552                       NaN  아이가 생기고 세상을 좀 더 따뜻한 시선으로 바라보게 된 것 같아.  3\n",
       "11559                       NaN             친구들에게 왕따를 당하고 있어. 그래도 괜찮아.  3\n",
       "11561                       NaN     옆집 김 씨가 수술 자금을 빌려갔는데 천천히 갚으려고 하려고.  3\n",
       "11568                       NaN       부동산 임대 소득으로 현재 여유롭게 살 수 있어서 좋단다.  3\n",
       "\n",
       "[30997 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#raw_df.loc[(raw_df['상황'] == \"neutral\"), '상황'] = 0  #중립 => 0\n",
    "#raw_df.loc[(raw_df['상황'] == \"peace\"), '상황'] = 0\n",
    "raw_df.loc[(raw_df['상황'] == \"anger\"), '상황'] = 0  #화남 => 1\n",
    "raw_df.loc[(raw_df['상황'] == \"angry\"), '상황'] = 0 \n",
    "raw_df.loc[(raw_df['상황'] == \"disgust\"), '상황'] = 0  #화남 => 1\n",
    "raw_df.loc[(raw_df['상황'] == \"sad\"), '상황'] = 1  #슬픔 => 2\n",
    "raw_df.loc[(raw_df['상황'] == \"sadness\"), '상황'] = 1  #슬픔 => 2\n",
    "raw_df.loc[(raw_df['상황'] == \"happiness\"), '상황'] = 2  #기쁨 => 3\n",
    "raw_df.loc[(raw_df['상황'] == \"peace\"), '상황'] = 3  #평온 \n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a7fe9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11459\n",
       "1     9333\n",
       "2     7402\n",
       "3     2803\n",
       "Name: 상황, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[\"상황\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4644ce06",
   "metadata": {},
   "source": [
    "# 3. 모델링과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1eddba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4dc95d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobert import get_tokenizer\n",
    "from kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6c44ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adc6fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPU\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00fd6481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['어, 청소 니가 대신 해 줘!', '0'],\n",
       " ['둘 다 청소 하기 싫어. 귀찮아.', '0'],\n",
       " ['둘 다 하기 싫어서 화내.', '0'],\n",
       " ['그럼 방세는 어떡해.', '0'],\n",
       " ['어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.', '0'],\n",
       " ['처음 학원에서 만났다가 서로 좋아해서 사귀게 되었지.', '1'],\n",
       " ['내가 애정 표현을 잘 못해서 자주 싸우긴 했어.', '1'],\n",
       " ['오늘 헤어졌어.', '1'],\n",
       " ['룸메이트와 너무 자주 싸우게 돼.', '0'],\n",
       " ['그러고 싶은데 보증금 때문에 그럴 수가 없어.', '0']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = []\n",
    "for ques, label in zip(raw_df['발화문'], raw_df['상황'])  :\n",
    "    data = []   \n",
    "    data.append(ques)\n",
    "    data.append(str(label))\n",
    "\n",
    "    data_list.append(data)\n",
    "data_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9cc73ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer,vocab, max_len,\n",
    "                 pad, pair):\n",
    "   \n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len,vocab=vocab, pad=pad, pair=pair)\n",
    "        \n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "         \n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f44b3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd86dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train & test 데이터로 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_train, dataset_test = train_test_split(data_list, test_size=0.2, shuffle=True, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ffd13e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/piai/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "data_train = BERTDataset(dataset_train, 0, 1, tok, vocab, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test,0, 1, tok, vocab,  max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a625022",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53e1d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=4,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        else:\n",
    "            out = pooler\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27323ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec90f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6bbea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fb66fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b5831e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6f938a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86577d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37573523746641fc9cf818cccd4b822c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 1.3813884258270264 train acc 0.3125\n",
      "epoch 1 batch id 201 loss 0.366529643535614 train acc 0.5830223880597015\n",
      "epoch 1 train acc 0.7010225959829364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf82f5490fd4f95ba28e82b5c226a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.8612389543446244\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ce0cf2fa2c43afbc9a519ea62625fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.5539357662200928 train acc 0.765625\n",
      "epoch 2 batch id 201 loss 0.2065213918685913 train acc 0.8576648009950248\n",
      "epoch 2 train acc 0.8725837628865979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae8f2398de949e2a0ae86da26cfa3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.8637932621502209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d2fc00e17248149e11e63cd7ad2dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.6198854446411133 train acc 0.78125\n",
      "epoch 3 batch id 201 loss 0.14507260918617249 train acc 0.8975435323383084\n",
      "epoch 3 train acc 0.9083440721649485\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ecd2e609eb40598eece1e3cebaadb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.8705817378497791\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b546288513964ec3bb945cad1c1420b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.3663376271724701 train acc 0.828125\n",
      "epoch 4 batch id 201 loss 0.1076926738023758 train acc 0.9233519900497512\n",
      "epoch 4 train acc 0.9311372422680413\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb283710f8244aabbbb1945c67f9cd23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.8784057437407953\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d7701b87984fb59c1946cc3757d787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.3540990650653839 train acc 0.859375\n",
      "epoch 5 batch id 201 loss 0.09654102474451065 train acc 0.9375777363184079\n",
      "epoch 5 train acc 0.9451514175257731\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1151e884c8416290f10899c9dc6f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.8792111561119292\n"
     ]
    }
   ],
   "source": [
    "train_history=[]\n",
    "test_history=[]\n",
    "loss_history=[]\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
    "    test_history.append(test_acc / (batch_id+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079dbb36",
   "metadata": {},
   "source": [
    "# 4. 모델테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3896322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, vocab, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "\n",
    "            if np.argmax(logits) == 0:\n",
    "                test_eval.append(\"화남이\")\n",
    "            elif np.argmax(logits) == 1:\n",
    "                test_eval.append(\"슬픔이\")\n",
    "            elif np.argmax(logits) == 2:\n",
    "                test_eval.append(\"기쁨이\")\n",
    "            elif np.argmax(logits) == 3:\n",
    "                test_eval.append(\"평온이\")\n",
    "\n",
    "\n",
    "        print(\">> 입력하신 내용에서 \" + test_eval[0] + \" 느껴집니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4525bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 : 어렵네\n",
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 배고파\n",
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 오늘 1등했어\n",
      ">> 입력하신 내용에서 기쁨이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 집에 오면서 넘어졌어\n",
      ">> 입력하신 내용에서 화남이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 오늘 상사한테 혼났어\n",
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 오늘 월급날이야\n",
      ">> 입력하신 내용에서 평온이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 오늘 월급날이야!\n",
      ">> 입력하신 내용에서 기쁨이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 오늘 별일없었어\n",
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 오늘 아무일도 없었어\n",
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 0\n"
     ]
    }
   ],
   "source": [
    "#질문 무한반복하기! 0 입력시 종료\n",
    "end = 1\n",
    "while end == 1 :\n",
    "    sentence = input(\"하고싶은 말을 입력해주세요 : \")\n",
    "    if sentence == \"0\" :\n",
    "        break\n",
    "    predict(sentence)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
